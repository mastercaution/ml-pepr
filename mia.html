

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Membership Inference Attack &mdash; ML-PePR alpha documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Generalized Membership Inference Attack (Direct)" href="gmia.html" />
    <link rel="prev" title="Privacy Attacks" href="privacy_attacks.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> ML-PePR
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="quick_start_guide.html">Quick-Start Guide</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="privacy_attacks.html">Privacy Attacks</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Membership Inference Attack</a></li>
<li class="toctree-l2"><a class="reference internal" href="gmia.html">Generalized Membership Inference Attack (Direct)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="robustness_attacks.html">Robustness Attacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="utilities.html">Utilities</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">ML-PePR</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="privacy_attacks.html">Privacy Attacks</a> &raquo;</li>
        
      <li>Membership Inference Attack</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/mia.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="membership-inference-attack">
<h1>Membership Inference Attack<a class="headerlink" href="#membership-inference-attack" title="Permalink to this headline">¶</a></h1>
<dl class="py class">
<dt id="pepr.privacy.mia.Mia">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">pepr.privacy.mia.</span></code><code class="sig-name descname"><span class="pre">Mia</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">attack_alias</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attack_pars</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_conf</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_models</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pepr.privacy.mia.Mia" title="Permalink to this definition">¶</a></dt>
<dd><p>Membership Inference Attacks (MIA) Against Machine Learning Models.</p>
<p>Attack-Steps:</p>
<ol class="arabic simple">
<li><p>Create dataset mapping for shadow models.</p></li>
<li><p>Train shadow models.</p></li>
<li><p>Generate attack model dataset.</p></li>
<li><p>Train attack models.</p></li>
<li><p>Evaluate attack models.</p></li>
</ol>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>attack_alias</strong> (<em>str</em>) – Alias for a specific instantiation of the mia class.</p></li>
<li><p><strong>attack_pars</strong> (<em>dict</em>) – <p>Dictionary containing all needed attack parameters:</p>
<ul>
<li><p>number_classes (int): Number of different classes the target model predicts.</p></li>
<li><p>number_shadow_models (int): Number of shadow models to be trained.</p></li>
<li><p>shadow_training_set_size (int): Size of the trainings set for each
shadow model. The corresponding evaluation sets will have the same size.</p></li>
<li><p>create_compile_shadow_model (function): Function that returns a compiled
TensorFlow model (typically identical to the target model) used in the
training of the shadow models.</p></li>
<li><p>create_compile_attack_model (function): Function that returns a compiled
TensorFlow model used for the attack models. The model output is expected to
be a single floating-point value per prediction.</p></li>
<li><p>shadow_epochs (int): Number of training epochs of the shadow models.</p></li>
<li><p>shadow_batch_size (int): Batch size used in the training of the
shadow models.</p></li>
<li><p>attack_epochs (int): Number of training epochs of the attack models.</p></li>
<li><p>attack_batch_size (int): Batch size used in the training of the
attack models.</p></li>
</ul>
</p></li>
<li><p><strong>data</strong> (<em>numpy.ndarray</em>) – Dataset with all training samples used in the given pentesting setting.</p></li>
<li><p><strong>labels</strong> (<em>numpy.ndarray</em>) – Array of all labels used in the given pentesting setting.</p></li>
<li><p><strong>data_conf</strong> (<em>dict</em>) – <p>Dictionary describing which record-indices are used to train the shadow
models, the target model(s) and which are used for the evaluation of the
attack.</p>
<ul>
<li><p>shadow_indices (list): List of indices describing which of the records
from data are used to train the shadow models.</p></li>
<li><p>target_indices (list): List of indices describing which of the records
from data were used to train the target model(s).</p></li>
<li><p>evaluation_indices (list): List of indices describing which of the records
from data are used to evaluate the attack.</p></li>
<li><p>record_indices_per_target (numpy.ndarray): n*m array describing for all n
target models which m indices where used in the training.</p></li>
</ul>
</p></li>
<li><p><strong>target_models</strong> (<em>iterable</em>) – List of target models which should be tested.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt id="pepr.privacy.mia.Mia.attack_alias">
<code class="sig-name descname"><span class="pre">attack_alias</span></code><a class="headerlink" href="#pepr.privacy.mia.Mia.attack_alias" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for a specific instantiation of the attack class.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="pepr.privacy.mia.Mia.attack_pars">
<code class="sig-name descname"><span class="pre">attack_pars</span></code><a class="headerlink" href="#pepr.privacy.mia.Mia.attack_pars" title="Permalink to this definition">¶</a></dt>
<dd><p>Dictionary containing all needed parameters fo the attack.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="pepr.privacy.mia.Mia.data">
<code class="sig-name descname"><span class="pre">data</span></code><a class="headerlink" href="#pepr.privacy.mia.Mia.data" title="Permalink to this definition">¶</a></dt>
<dd><p>Dataset with all training samples used in the given pentesting setting.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>numpy.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="pepr.privacy.mia.Mia.labels">
<code class="sig-name descname"><span class="pre">labels</span></code><a class="headerlink" href="#pepr.privacy.mia.Mia.labels" title="Permalink to this definition">¶</a></dt>
<dd><p>Array of all labels used in the given pentesting setting.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>numpy.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="pepr.privacy.mia.Mia.data_conf">
<code class="sig-name descname"><span class="pre">data_conf</span></code><a class="headerlink" href="#pepr.privacy.mia.Mia.data_conf" title="Permalink to this definition">¶</a></dt>
<dd><p>Dictionary describing the data configuration of the given pentesting
setting by specifying which record-indices are used to train the shadow
models, the target model(s) and which are used for the evaluation of the
attack.</p>
<ul class="simple">
<li><p>shadow_indices (list): List of indices describing which of the records
from data are used to train the shadow models.</p></li>
<li><p>target_indices (list): List of indices describing which of the records
from data were used to train the target model(s).</p></li>
<li><p>evaluation_indices (list): List of indices describing which of the records
from data are used to evaluate the attack.</p></li>
<li><p>record_indices_per_target (numpy.ndarray): n*m array describing for all n
target models which m indices where used in the training.</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="pepr.privacy.mia.Mia.target_models">
<code class="sig-name descname"><span class="pre">target_models</span></code><a class="headerlink" href="#pepr.privacy.mia.Mia.target_models" title="Permalink to this definition">¶</a></dt>
<dd><p>List of target models which should be tested.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>iterable</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="pepr.privacy.mia.Mia.attack_results">
<code class="sig-name descname"><span class="pre">attack_results</span></code><a class="headerlink" href="#pepr.privacy.mia.Mia.attack_results" title="Permalink to this definition">¶</a></dt>
<dd><p>Dictionary storing the attack model results. A list “per attack model and
target model” has the shape (attack model, target model) -&gt; First index
specifies the attack model, the second index the target model.</p>
<ul class="simple">
<li><p>tp_list (numpy.ndarray): True positives per attack model and target model.</p></li>
<li><p>fp_list (numpy.ndarray): False positives per attack model and target model.</p></li>
<li><p>fn_list (numpy.ndarray): False negatives per attack model and target model.</p></li>
<li><p>tn_list (numpy.ndarray): True negatives per attack model and target model.</p></li>
<li><p>eval_accuracy_list (numpy.ndarray): Evaluation accuracy on evaluation records
per attack model and target model.</p></li>
<li><p>precision_list (numpy.ndarray): Attack precision per attack model and target
model.</p></li>
<li><p>recall_list (numpy.ndarray): Attack recall per attack model and target model.</p></li>
<li><p>eval_accuracy (numpy.ndarray): Evaluation accuracy averaged over all attack
models per target model.</p></li>
<li><p>precision (numpy.ndarray): Attack precision averaged over all attack models
per target model.</p></li>
<li><p>recall (numpy.ndarray): Attack recall averaged over all attack models per
target model.</p></li>
<li><p>overall_eval_accuracy (float): Evaluation accuracy averaged over all target
models.</p></li>
<li><p>overall_precision (float): Attack precision averaged over all target models.</p></li>
<li><p>overall_recall (float): Attack recall averaged over all target models.</p></li>
<li><p>shadow_train_accuracy_list (list): Accuracy on training records per shadow
model and target model.</p></li>
<li><p>shadow_eval_accuracy_list (list): Accuracy on evaluation records per shadow
model and target model.</p></li>
<li><p>shadow_train_accuracy (float): Accuracy on train records averaged over all
shadow models per target model.</p></li>
<li><p>shadow_eval_accuracy (float): Accuracy on evaluation records averaged over all
shadow models per target model.</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">References</p>
<p>Implementation of the basic membership inference attack by Reza Shokri, Marco
Stronati, Congzheng Song and Vitaly Shmatikov. Membership inference attacks
against machine learning models 2017 IEEE Symposium on Security and Privacy (SP).
IEEE, 2017.</p>
<dl class="py method">
<dt id="pepr.privacy.mia.Mia.create_attack_report">
<code class="sig-name descname"><span class="pre">create_attack_report</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mia_report'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pdf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pepr.privacy.mia.Mia.create_attack_report" title="Permalink to this definition">¶</a></dt>
<dd><p>Create an attack report just for the given attack instantiation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>save_path</strong> (<em>str</em>) – Path to save the tex, pdf and asset files of the attack report.</p></li>
<li><p><strong>pdf</strong> (<em>bool</em>) – If set, generate pdf out of latex file.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="pepr.privacy.mia.Mia.create_attack_section">
<code class="sig-name descname"><span class="pre">create_attack_section</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">save_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pepr.privacy.mia.Mia.create_attack_section" title="Permalink to this definition">¶</a></dt>
<dd><p>Create an attack section for the given attack instantiation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>save_path</strong> – Path to save the tex, pdf and asset files of the attack report.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="pepr.privacy.mia.Mia.run">
<code class="sig-name descname"><span class="pre">run</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">load_pars</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pepr.privacy.mia.Mia.run" title="Permalink to this definition">¶</a></dt>
<dd><p>Run membership inference attack.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>save_path</strong> (<em>str</em>) – <p>If path is given, the following (partly computational expensive)
intermediate results are saved to disk:</p>
<ul>
<li><p>The mapping of training-records to shadow models.</p></li>
<li><p>The trained shadow models.</p></li>
<li><p>The attack datasets for training the attack model.</p></li>
<li><p>The trained attack models.</p></li>
</ul>
</p></li>
<li><p><strong>load_pars</strong> (<em>dict</em>) – <p>If this dictionary is given, the following computational intermediate
results can be loaded from disk.</p>
<ul>
<li><p>shadow_data_indices (str) : Path to shadow data mapping.</p></li>
<li><p>shadow_models (list) : List of paths to shadow models.</p></li>
<li><p>attack_datasets (str) : Path to attack datasets.</p></li>
<li><p>attack_models (list) : List of paths to attack models.</p></li>
</ul>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="gmia.html" class="btn btn-neutral float-right" title="Generalized Membership Inference Attack (Direct)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="privacy_attacks.html" class="btn btn-neutral float-left" title="Privacy Attacks" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Institute for IT-Security (University of Luebeck).

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>